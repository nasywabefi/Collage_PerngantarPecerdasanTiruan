# -*- coding: utf-8 -*-
"""PKT_FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sHQV16D1NrZ61cnDnYzDmYtcLrpGwHPd

#Movie Recommedation

Final Project PKT
Nasywa Befiputri - 2203015044

##library
"""

!pip install scikit-surprise

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
import numpy as np
import pandas as pd

"""##load dataset


"""

url = "https://raw.githubusercontent.com/nasywabefi/Collage_PerngantarPecerdasanTiruan/main/finalsubmission/netflix_data.csv"
data = pd.read_csv(url)

"""##cek data"""

data.head()

data.info()

data.release_year.view()

"""##bersihin data yang kosong"""

data.fillna({
    'director': '',
    'cast': '',
    'description': '',
    'rating': 'Unknown',
    'duration': '0 min',
    'country': '',
    'date_added': ''
}, inplace=True)

"""mensimulasikan data pengguna (user_id)"""

data['user_id'] = np.random.randint(1, 1001, size=len(data))

""" Kategori Rating ke Nilai Numerik"""

rating_map = {
    'Unknown': 0, 'G': 1, 'PG': 2, 'PG-13': 3, 'R': 4, 'NC-17': 5
}

data['rating'] = data['rating'].map(rating_map).fillna(0).astype(int)

"""Content Based FIltering"""

# TF-IDF
tfidf = TfidfVectorizer(stop_words='english')

# Combine description, director, cast, and listed_in as content features
content_matrix = tfidf.fit_transform(
    data['description'] + " " + data['director'] + " " + data['cast'] + " " + data['listed_in']
)


content_similarity = cosine_similarity(content_matrix)

"""Collaborative Filtering"""

# Collaborative Filtering

# Menginisialisasi Reader untuk memproses data rating
reader = Reader(rating_scale=(1, 5))


# Membuat dataset dari DataFrame
rating_data = Dataset.load_from_df(data[['user_id', 'title', 'rating']], reader)

# Membagi dataset menjadi data latih dan uji
trainset, testset = train_test_split(rating_data, test_size=0.2)

# Menginisialisasi model Singular Value Decomposition (SVD)
svd_model = SVD()

# Melatih model SVD dengan data latih
svd_model.fit(trainset)

"""Hybrid"""

# Hybrid Recommendation System
class HybridFlixHub:
    def __init__(self, content_sim, svd_model, data):
        # Inisialisasi dengan matriks similarity berbasis konten, model SVD untuk collaborative filtering, dan data film.
        self.content_sim = content_sim  # Matriks similarity berbasis konten
        self.svd_model = svd_model      # Model collaborative filtering (SVD)
        self.data = data                # Dataframe berisi informasi film dan metadata

    def recommend(self, title, alpha=0.5, beta=0.5, n=10):

        # Cari indeks film yang cocok dengan judul input
        idx = self.data[self.data['title'].str.contains(title, case=False, na=False)].index
        if len(idx) == 0:  # kalau ga ketemu film dengan judul tersebut, kembalikan list kosong
            return []
        content_scores = self.content_sim[idx[0]]  # Ambil skor similaritas berbasis konten untuk film tersebut

        # Hitung skor collaborative filtering menggunakan model SVD
        unique_titles = self.data['title'].unique()  # Dapatkan semua judul film unik
        collaborative_scores = [
            (movie, self.svd_model.predict(1, movie).est)  # Prediksi skor untuk user_id=1 (dummy user)
            for movie in unique_titles
        ]
        collaborative_scores = {movie: score for movie, score in collaborative_scores}  # Konversi ke dictionary

        # Gabungkan skor content-based dan collaborative untuk menghasilkan hybrid score
        hybrid_scores = []
        for i, movie in enumerate(unique_titles):
            content_score = content_scores[i]  # Ambil skor similaritas berbasis konten
            collaborative_score = collaborative_scores.get(movie, 0)  # Ambil skor collaborative atau 0 jika tidak ada
            # Hitung skor hybrid sebagai kombinasi linier dari content dan collaborative scores
            hybrid_score = alpha * content_score + beta * collaborative_score
            hybrid_scores.append((movie, hybrid_score))

        # Urutkan film berdasarkan skor hybrid secara descending, lalu ambil n rekomendasi teratas
        hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)[:n]
        return [rec[0] for rec in hybrid_scores]  # Kembalikan hanya judul film

# Create Hybrid System

# Menginisialisasi sistem rekomendasi hybrid menggunakan kelas HybridFlixHub
hybrid_system = HybridFlixHub(content_similarity, svd_model, data)

"""Outcome"""

# Meminta pengguna untuk memasukkan judul film yang akan dijadikan referensi rekomendasi.
movie_title = input("Masukkan judul film untuk mendapatkan rekomendasi: ")

# Menggunakan sistem rekomendasi hybrid untuk mendapatkan daftar rekomendasi berdasarkan judul film yang diberikan.
recommendations = hybrid_system.recommend(movie_title)

# Display Recommendations
if recommendations:
    # Jika terdapat rekomendasi, tampilkan hasilnya.
    print(f"\nRekomendasi untuk film '{movie_title}':")
    for idx, rec in enumerate(recommendations, start=1):
        # Menampilkan daftar rekomendasi satu per satu dengan format terurut.
        print(f"{idx}. {rec}")
else:
    # Jika tidak ada film yang cocok atau mirip dengan judul yang diberikan, beri pesan pemberitahuan.
    print(f"Tidak ditemukan film yang mirip dengan judul '{movie_title}'")

from surprise import accuracy

# Evaluasi model menggunakan dataset uji
predictions = svd_model.test(testset)

# Menghitung metrik evaluasi
mae = accuracy.mae(predictions, verbose=True)  # Mean Absolute Error
rmse = accuracy.rmse(predictions, verbose=True)  # Root Mean Square Error

# Maksimum rating dalam dataset
max_rating = 5  # Karena rating scale adalah (1-5)

# Menghitung persentase akurasi
mae_accuracy = (1 - mae / max_rating) * 100
rmse_accuracy = (1 - rmse / max_rating) * 100

print(f"\nPersentase Akurasi Berdasarkan MAE: {mae_accuracy:.2f}%")
print(f"Persentase Akurasi Berdasarkan RMSE: {rmse_accuracy:.2f}%")